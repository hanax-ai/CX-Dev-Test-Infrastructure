#!/usr/bin/env python3
"""
Citadel Alpha API Gateway
FastAPI application for LLM orchestration and RAG pipeline
"""

from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
import structlog
import uvicorn
from contextlib import asynccontextmanager

from config import settings
from routers import auth, chat, rag

# Configure structured logging
logger = structlog.get_logger()

# Rate limiter
limiter = Limiter(key_func=get_remote_address)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan events"""
    logger.info("Starting Citadel Alpha API Gateway", version="{{ app_version }}")
    
    # Startup
    await initialize_services()
    
    yield
    
    # Shutdown
    logger.info("Shutting down Citadel Alpha API Gateway")
    await cleanup_services()

# FastAPI app instance
app = FastAPI(
    title="{{ app_name }}",
    description="Citadel Alpha API Gateway - LLM Orchestration & RAG Pipeline",
    version="{{ app_version }}",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# Middleware configuration
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

app.add_middleware(
    CORSMiddleware,
    allow_origins={{ security.cors_origins | to_json }},
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["{{ ansible_default_ipv4.address }}", "localhost", "127.0.0.1"]
)

# Include routers
app.include_router(auth.router, prefix="/api/v1/auth", tags=["authentication"])
app.include_router(chat.router, prefix="/api/v1/chat", tags=["chat"])
app.include_router(rag.router, prefix="/api/v1/rag", tags=["rag"])

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "version": "{{ app_version }}",
        "timestamp": "{{ ansible_date_time.iso8601 }}",
        "services": await check_service_health()
    }

@app.get("/api/v1/models")
@limiter.limit("{{ security.rate_limiting.requests_per_minute }}/minute")
async def get_available_models(request):
    """Get available LLM models across all servers"""
    from services import llm_service
    
    try:
        models = await llm_service.get_all_models()
        return {"models": models}
    except Exception as e:
        logger.error("Failed to fetch models", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Unable to fetch available models"
        )

@app.get("/metrics")
async def get_metrics():
    """Prometheus metrics endpoint"""
    from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
    from fastapi import Response
    
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

async def initialize_services():
    """Initialize all services on startup"""
    from services import database_service, vector_service, llm_service
    
    try:
        await database_service.initialize()
        await vector_service.initialize()
        await llm_service.initialize()
        logger.info("All services initialized successfully")
    except Exception as e:
        logger.error("Failed to initialize services", error=str(e))
        raise

async def cleanup_services():
    """Cleanup services on shutdown"""
    from services import database_service, vector_service
    
    try:
        await database_service.cleanup()
        await vector_service.cleanup()
        logger.info("All services cleaned up successfully")
    except Exception as e:
        logger.error("Error during service cleanup", error=str(e))

async def check_service_health():
    """Check health of all dependent services"""
    from services import database_service, vector_service, llm_service
    
    health_status = {}
    
    try:
        health_status["database"] = await database_service.health_check()
        health_status["vector_db"] = await vector_service.health_check()
        health_status["llm_servers"] = await llm_service.health_check()
    except Exception as e:
        logger.error("Health check failed", error=str(e))
        health_status["error"] = str(e)
    
    return health_status

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="{{ app_host }}",
        port={{ app_port }},
        workers={{ app_workers }},
        reload=False,
        log_level="{{ logging.level | lower }}",
        access_log=True
    )
