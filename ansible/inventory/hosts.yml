---
# CX Infrastructure Ansible Inventory
# Embedding Model Deployment Configuration

all:
  children:
    ai_servers:
      hosts:
        cx-llm-01:
          ansible_host: 192.168.10.29
          ansible_user: agent0
          ansible_ssh_private_key_file: ~/.ssh/id_rsa
          model_type: chat  # For Llama 3 Chat
          model_storage_path: "/opt/ai_models"
          gpu_count: 2
          gpu_type: "RTX 4070 Ti SUPER"
          ollama_host: "0.0.0.0"
          ollama_port: 11434
          
        cx-llm-02:
          ansible_host: 192.168.10.28
          ansible_user: agent0
          ansible_ssh_private_key_file: ~/.ssh/id_rsa
          model_type: instruct  # For Llama 3 Instruct
          model_storage_path: "/opt/ai_models"
          gpu_count: 2
          gpu_type: "RTX 5060 Ti"
          ollama_host: "0.0.0.0"
          ollama_port: 11434
          
        cx-orc:
          ansible_host: 192.168.10.31
          ansible_user: agent0
          ansible_ssh_private_key_file: ~/.ssh/id_rsa
          model_type: embeddings  # For Llama 3 Embeddings
          model_storage_path: "/opt/ai_models"
          gpu_enabled: true
          gpu_count: 1
          gpu_type: "RTX 5060 Ti"
          ollama_host: "0.0.0.0"
          ollama_port: 11434
          cuda_version: "12.9"

  vars:
    # Global Configuration
    python_version: "3.12.3"
    conda_env: "ai_env"
    nvidia_driver_version: "575.64.03"
    ollama_version: "0.9.6"
    
    # Model Configuration
    embedding_models:
      - name: "mxbai-embed-large"
        size: "334M"
        description: "Large embedding model for high-quality text representations"
      - name: "nomic-embed-text"
        size: "137M" 
        description: "Efficient text embedding model"
      - name: "all-minilm:22m"
        size: "22M"
        description: "Lightweight embedding model for fast inference"
